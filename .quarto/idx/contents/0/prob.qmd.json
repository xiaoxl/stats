{"title":"Probability theory","markdown":{"headingText":"Probability theory","containsRefs":false,"markdown":"\n\n\n{{< include ../math.qmd >}}\n\n\n\n\n## Notations\n- $Y$: a random variable (captial letters)\n- $y$: a sample of $Y$\n- $\\Pr\\qty(Y\\in A\\mid\\theta)$: the probability of $Y$ being in $A$\n- $p(y\\mid\\theta)=\\Pr\\qty(Y=y\\mid\\theta)$: the discrete probability density function\n- $f(y\\mid\\theta)=\\displaystyle\\dv{y}\\Pr\\qty(Y\\leq y\\mid\\theta)$: the continuous probability density function\n- $\\Exp\\qty(Y)$: the expectation of $Y$\n- $\\Var\\qty(Y)$: the variance of $Y$\n\n\n\n## Random variables\n\n\n::: {#def-}\n# Expectation\n$$\n\\Exp\\mqty[u(X)] = \\int_{-\\infty}^{\\infty}u(x)f(x)\\dl3x.\n$$\n:::\n\n\n::: {#def-}\n1. $\\mu=\\Exp(X)$ is called the **mean value** of $X$.\n2. $\\sigma^2=\\Var(X)=\\Exp\\mqty[(X-\\mu)^2]$ is called the **variance** of $X$.\n3. $M_X(t)=\\Exp\\mqty[\\me^{tX}]$ is called the **moment generating function** of $X$.\n:::\n\n\n::: {#prp-}\n1. $\\Exp\\mqty[ag(X)+bh(X)]=a\\Exp\\mqty[g(X)]+b\\Exp\\mqty[h(X)]$.\n2. $\\Var\\mqty[X]=\\Exp\\mqty[(X-\\mu)^2]=\\Exp(X^2)-\\mu^2$.\n:::\n\n::: {.proof}\n\n$$\n\\begin{split}\n\\Exp\\mqty[ag(X)+bh(X)]&=\\int_{-\\infty}^{\\infty}\\mqty[ag(x)+bh(x)]f(x)\\dl3x\\\\\n                 &=a\\int_{-\\infty}^{\\infty}g(x)f(x)\\dl3x+b\\int_{-\\infty}^{\\infty}h(x)f(x)\\dl3x\\\\\n                 &=a\\Exp\\mqty[g(X)]+b\\Exp\\mqty[h(X)].\n\\end{split}\n$$\n\n$$\n\\begin{split}\n\\Exp\\mqty[(X-\\mu)^2]&=\\Exp\\mqty[\\qty(X^2-2\\mu X+\\mu^2)]=\\Exp(X^2)-2\\mu\\Exp(X)+\\Exp(\\mu^2)\\\\\n&=\\Exp(X^2)-2\\mu\\mu+\\mu^2=\\Exp(X^2)-\\mu^2.\n\\end{split}\n$$\n:::\n\n### R code\nR has built-in random variables with different distributions. The naming convention is a prefix `d-`, `p-`, `q-` and `r-` together with the name of distribution. \n\n- `d-`: density function of the given distribution;\n- `p-`: cumulative density function of the given distribution;\n- `q-`: quantile function of the given distribution (which is the inverse of `p-` function);\n- `r-`: random sampling from the given distribution.\n\n\n::: {.callout-tip collapse=\"true\"}\n# Examples: normal distribution\n\n\n```{r}\nx <- seq(-4, 4, length=100)\ny <- dnorm(x, mean=2, sd=0.5)\nplot(x, y, type=\"l\")\n```\n\n\n```{r}\nx <- seq(-4, 4, length=100)\ny <- pnorm(x, mean=2, sd=0.5)\nplot(x, y, type=\"l\")\n```\n\n\n```{r}\nqnorm(0)\nqnorm(0.5)\nqnorm(1)\n```\n\n\n```{r}\nrnorm(10)\n```\n\n\n:::\n\n## Random vectors\n\n\n\n::: {#def-randomvector}\n# Random vector\nGiven a random experiment with a sample space $\\mathcal C$, consider two random variables $X_1$ and $X_2$, which assign to each element $c$ of $\\mathcal C$ one and only one ordered pair of numbers $X_1(c)=x_1$, $X_2(c)=x_2$. Then we say that $(X_1, X_2)$ is a **random vector**. The **space** of $(X_1, X_2)$ is the set of orderd pairs $\\mathcal D=\\set{(x_1, x_2)\\mid x_1=X_1(c), x_2=X_2(c), c\\in\\mathcal C}$.\n:::\n\n\n::: {#def-cdf}\n# Joint Cumulative Distribution Function\n**The joint cumulative distribution function** of $(X_1, X_2)$ is defined as follows.\n\n<!-- $$\nF_{X_1,X_2}(x_1,x_2)=\\pr\\sqb{\\set{X_1\\leq x_1}\\cap\\set{X_2\\leq x_2}}.\n$$\nIn continuous case,  -->\n$$\nF_{X_1,X_2}(x_1,x_2)=\\int_{-\\infty}^{x_1}\\int_{-\\infty}^{x_2}f_{X_1,X_2}(w_1,w_2)\\dl3w_1\\dl3w_2.\n$$\n:::\n\n\n<!-- ::: {#def-pdf}\n# Joint probability mass function (pmf)\nIn discrete random vector case, the **pmf** is defined as  \n$$\np_{X_1,X_2}(x_1,x_2)=\\pr\\sqb{X_1=x_1,X_2=x_2}.\n$$\n::: -->\n\n::: {#def-cdf}\n# Joint probability density function (pdf)\nIn continuous random vector case, the **pdf** is defined as  \n$$\nf_{X_1, X_2}(x_1, x_2)=\\frac{\\partial^2F_{X_1, X_2}(x_1,x_2)}{\\partial x_1\\partial x_2}.\n$$\n:::\n\n\n\n\n::: {#def-marginal}\n## Marginal pdf\nAssume $(X_1, X_2)$ be a continuous random vector. The **marginal pdf** is \n$$\nf_{X_1}(x_1)=\\int_{-\\infty}^{\\infty}f(x_1, x_2)\\dl3x_2.\n$$\n:::\n\n\n\n\n::: {#def-}\n# Expectation\nAssume that $Y=g(X_1, X_2)$. Then\n$$\n\\Exp(Y)=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} g(x_1, x_2) f_{X_1, X_2}(x_1,x_2)\\dl3x_1\\dl3x_2.\n$$\n:::\n\n\n\n\n\n::: {#def-conditionaldistribution}\n# Conditional probability\nThe conditional pdf is defined as follows:\n$$\nf_{X_1\\mid X_2}(x_1\\mid x_2)=\\frac{f_{X_1,X_2}(x_1,x_2)}{f_{X_1}(x_1)}=\\frac{f_{X_1,X_2}(x_1,x_2)}{\\int_{-\\infty}^{\\infty} f_{X_1,X_2}(x_1,w)\\dl3w},\n$$\nand the corresponding conditional probability is defined as\n$$\n\\Pr(X_1\\in A\\mid X_2=x_2)=\\int_Af_{X_1\\mid X_2}(x_1\\mid x_2)\\dl3x_1.\n$$\nThus $f_{X_1\\mid X_2}(x_1\\mid x_2)$ is a pdf of a random function of $X_1$.\n:::\n\n\n::: {#thm-}\nLet $(X_1, X_2)$ be a random vector such that $\\Var(X_2)$ is finite. $\\Exp(X_2\\mid X_1=x_1)$ and $\\Var(X_2\\mid X_1=x_1)$ can be seen as random functions of $X_1$. Then\n\na. $\\Exp\\mqty[\\Exp(X_2\\mid X_1)]=\\Exp(X_2)$.\nb. $\\Var\\mqty[\\Var(X_2\\mid X_1)]\\leq\\Var(X_2)$.\n:::\n\n\n\n### Relations to single variable case\nUnder the assumption of two variables $X$ and $Y$, when only talking about one variable $X$ (resp. $Y$), we are actually talking about the random variable corresponding to the marginal pdf. The ignoring the other variable part is handled by the integration part.\n\n\n::: {#prp-}\n1. $\\Exp_X\\mqty[u(X)]=\\Exp\\mqty[u(X)]$.\n2. $\\Var_X(X)=\\Var(X)$.\n:::\n\n\n::: {.proof}\n$$\n\\begin{aligned}\n\\Exp\\mqty[u(X)]&=\\iint u(x)f(x,y)\\dl3x\\dl3y=\\int u(x) \\mqty[\\displaystyle\\int f(x,y)\\dl3y]\\dl3x=\\int u(x)f_X(x)\\dl3x=\\Exp_X\\mqty[u(X)],\\\\\n\\Var(X)&=\\Exp\\mqty[(X-\\mu)^2]=\\Exp(X^2)-\\mu^2=\\Exp_X(X^2)-\\mu^2=\\Var_X(X).\n\\end{aligned}\n$$\n\n:::\n\n\n## Maximal likelihood estimation\nConsider the Bayes' Theorem \n\n$$\n    p(\\vb w\\mid \\mathcal D)=\\frac{p(\\mathcal D\\mid \\vb w)p(\\vb w)}{p(\\mathcal D)}.\n$$\n\n$p(\\mathcal D\\mid \\vb w)$ is called the *likelihood function*, $p(\\vb w)$ is called the *prior probability* and $p(\\vb w\\mid \\mathcal D)$ is called the *posterior probability*. A widely used frequentist estimator is *maximum likelihood*, in which $\\vb w$ is set to the value that maximizes the likelihood function $p(\\mathcal D\\mid \\vb w)$. Sometimes the likelihood function is changed to be the *error function* $-\\ln p$ and to maximize the likelihood function is the same as to minimize the error function.\n\n\n\nConsider a data set of observations $\\vb x=(x_1,x_2,\\ldots,x_N)^T$. These data are i.i.d., with respect to the Gaussian distribution $\\mathcal N(\\mu,\\sigma^2)$. Then we have the *likelihood function* if it is treated as a function of $\\mu$ and $\\sigma^2$:\n\n$$\n    p(\\vb x\\mid \\mu,\\sigma^2)=\\prod_{n=1}^N\\mathcal N(x_n\\mid \\mu,\\sigma^2).\n$$\nWe want to find $\\mu$ and $\\sigma^2$ to maximize the likelihood function. To do so, we would like to consider the error function \n\n$$\n\\begin{split}\n    -\\ln p(\\vb x\\mid \\mu,\\sigma^2)&=-\\ln \\prod_{n=1}^N\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp{-\\frac{1}{2\\sigma^2}(x_n-\\mu)^2}=\\sum_{n=1}^N\\qty(\\frac12\\ln(2\\pi\\sigma^2)+\\frac{1}{2\\sigma^2}(x_n-\\mu)^2)\\\\\n    &=\\frac{1}{2\\sigma^2}\\sum_{n=1}^N(x_n-\\mu)^2+\\frac{N}{2}\\ln(\\sigma^2)+\\frac{N}{2}\\ln(2\\pi).\n\\end{split}\n$$\n\nTake the derivative of it. We have\n\n$$\n   \\begin{split}\n       \\pdv{ \\qty(-\\ln p(\\vb x\\mid \\mu,\\sigma^2))}{\\mu}&=\\frac{1}{2\\sigma^2}\\sum_{n=1}^N2(x_n-\\mu)(-1)=-\\frac{1}{\\sigma^2}\\qty(N\\mu-\\sum_{n=1}^Nx_n),\\\\\n             \\pdv{ \\qty(-\\ln p(\\vb x\\mid \\mu,\\sigma^2))}{\\sigma^2}&=\\frac12(-1)(\\sigma^2)^{-2}\\qty(\\sum_{n=1}^N(x_n-\\mu)^2)+\\frac{N}{2}\\frac{1}{\\sigma^2}\\\\\n             &=-\\frac N{2(\\sigma^2)^2}\\qty(\\frac1N\\sum_{n-1}^N(x_n-\\mu)^2-\\sigma^2).\n   \\end{split} \n$$\nTo minimize the error function we need to let them be $0$. Then we have\n\n$$\n    \\mu_{ML}=\\sum_{n=1}^Nx_n,\\quad \\sigma^2_{ML}=\\frac1N\\sum_{n=1}^N(x_n-\\mu_{ML})^2.\n$$\n<!-- These are called the *sample mean* and the *sample variance* of the data. Note that the sample variance is measured with respect to the sample mean. -->\n\n\nCompute $\\Exp\\mqty[\\mu_{ML}]$ and $\\Exp\\mqty[\\sigma^2_{ML}]$.\n\n$$\n    \\Exp\\mqty[\\mu_{ML}]=\\Exp\\mqty[\\frac1N\\sum_{n=1}^Nx_n]=\\frac1N\\sum_{n=1}^N\\Exp\\mqty[x_n]=\\frac1NN\\mu=\\mu.\n$$\nSince $\\Var\\mqty[kx]=\\Exp\\mqty[(kx)^2]-(\\Exp\\mqty[kx])^2=k^2\\Exp\\mqty[x^2]-k^2\\Exp\\mqty[x]^2=k^2\\Var\\mqty[x]$, we have\n\n$$\n\\begin{aligned}\n    \\Var\\mqty[\\mu_{ML}]&=\\Var\\mqty[\\frac1N\\sum_{n=1}^Nx_n]=\\frac1{N^2}\\Var\\mqty[\\sum_{n=1}^Nx_n]=\\frac{1}{N^2}\\sum_{n=1}^N\\Var\\mqty[x_n]\\\\\n    &=\\frac{1}{N^2}(N\\sigma^2)=\\frac{1}{N}\\sigma^2,\\\\\n    \\Var\\mqty[x_n-\\mu_{ML}]&=\\Var\\mqty[\\frac{N-1}{N}x_n-\\frac1Nx_1-\\ldots-\\frac1Nx_N]\\\\\n    &=\\frac{(N-1)^2}{N^2}\\sigma^2+\\frac{1}{N^2}\\sigma^2+\\ldots+\\frac1{N^2}\\sigma^2\\\\\n    &=\\frac{N-1}{N}\\sigma^2.\n\\end{aligned}\n$$\nThen \n\n$$\n\\begin{split}\n    \\Exp\\mqty[\\sigma^2_{ML}]&=\\Exp\\mqty[\\frac1N\\sum_{n=1}^N(x_n-\\mu_{ML})^2]=\\frac1N\\sum_{n=1}^N\\Exp\\mqty[(x_n-\\mu_{ML})^2]\\\\\n    &=\\frac1N\\sum_{n=1}^N\\qty(\\Var\\mqty[x_n-\\mu_{ML}]+(\\Exp\\mqty[x_n-\\mu_{ML}])^2)=\\frac{N-1}{N}\\sigma^2.\n\\end{split}\n$$\n\n\nTherefore $\\sigma^2_{ML}$ is biased, and the unbiased variance estimation is \n\n$$\n    \\tilde{\\sigma}^2=\\frac{1}{N-1}\\sum_{n=1}^N(x_n-\\mu_{ML})^2.\n$$\n\n\n\n## \n\n\n::: {#thm-bayesthm}\n$$\nf_{X\\mid Y=y}(x)=\\frac{f_{Y\\mid X=x}(y\\mid x)f_X(x)}{f_Y(y)}\n$$\n:::\n\n\n\n::: {.callout-note}\n$f_{X\\mid Y}(x\\mid y)$ is a pdf w.r.t $X$, not a pdf w.r.t $Y$.\n:::\n\n\n\n\n::: {.cell-output-stdout}\n```\n# Heading 1\n\n## Heading 2\n\n```\n:::\n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"toc-depth":2,"output-file":"prob.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.530","number-depth":4,"bibliography":["../../book.bib"],"csl":"../../ims.csl","jupyter":"ds24","knitr":{"opts_chunk":{"comment":"#>","collapse":true}},"crossref":{"appendix-title":"Appendix ","appendix-delim":":"},"theme":"united"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}