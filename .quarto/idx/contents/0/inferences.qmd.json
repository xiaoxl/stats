{"title":"Inferences","markdown":{"headingText":"Inferences","containsRefs":false,"markdown":"\n\n{{< include ../math.qmd >}}\n\n\n\n## General theory\n\nCited from [@Hog2019, pp. 206, Chapter 4].\n\n### Sampling\n\n\nConsider a random variable $X$ with an unknown distribution. Our information about the distribution of $X$ comes from a sample on $X$: $\\qty{X_1,\\ldots,X_n}$.\n\n- The sample ovservations $\\qty{X_1,\\ldots,X_n}$ have the same distribution as $X$.\n- $n$ denotes the **sample size**.\n- When the sample is actually drawn, we use $x_1,\\ldots,x_n$ as the **realizations** of the sample.\n\n\n::: {#def-}\n# Random sample\nIf the random variables $X_1,\\ldots, X_n$ are iid, then these random variable constitute a **random sample** of size $n$ from the common distribution.\n:::\n\n\n::: {#def-}\n# Statistics\nLet $X_1,\\ldots,X_n$ denote a sample on a random variable $X$. Let $T=T(X_1,\\ldots,X_n)$ be a function of the sample. $T$ is called a **statistic**. Once a sample is drawn, $t=T(x_1,\\ldots,x_n)$ is called the *realization* of $T$. \n:::\n\n\n::: {#def-}\n# Sampling distribution\n- The distribution of $T$ is called the **sampling distribution**.\n- The standard deviation of the sampling distribution is called the **standard error of estimate**.\n:::\n\n\n\n::: {#thm-}\n# The Central Limit Theorem\nFor large sample sizes, the mean $\\bar{y}$ of a sample from a population with mean $\\mu$ and a standard deviation $\\sigma$ has a sampling distribution that is approximately normal.\n:::\n\n### Point estimation\n\nAssume that the distribution of $X$ is known down to an unknown parameter $\\theta$ where $\\theta$ can be a vector. Then the pdf of $X$ can be written as $f(x;\\theta)$. In this case we might find some statistic $T$ to estimate $\\theta$. This is called a **point estimator** of $\\theta$. A realization $t$ is called an **estimate** of $\\theta$.\n\n\n::: {#def-}\n# Unbiasedness\nLet $X_1,\\ldots,X_n$ is a sample on a random varaible $X$ with pdf $f(x;\\theta)$. Let $T$ be a statistic. We say that $T$ is an **unbiased** estimator of $\\theta$ if $E(T)=\\theta$.\n:::\n\n\n\nLet $X$ be a random variable, with mean $\\mu$ and variance $\\sigma^2$. Consider a sample $\\set{X_i}$ of size $n$. By definition all $X_i$'s are iid. Therefore $\\Exp\\qty(X_i)=\\mu$, and $\\Var\\qty(X_i)=\\sigma^2$ for any $i=1,\\ldots, N$.\n\nConsider the following statistics:\n\n- $\\bar{\\mu}=\\dfrac1N\\sum_{i=1}^NX_i$,\n- $\\bar{\\sigma}^2=\\dfrac{1}{N-1}\\sum_{i=1}^N(X_i-\\bar{\\mu})^2$.\n\n\n::: {#lem-}\n\n1. $\\Exp(\\bar{\\mu})=\\mu$.\n2. $\\Exp(\\bar{\\sigma}^2)=\\sigma^2$.\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n# Proof\n$$\n\\begin{aligned}\n\\Exp\\qty(\\bar{\\mu})&=\\Exp\\qty(\\frac1N\\sum_{i=1}^NX_i)=\\frac1N\\sum_{i=1}^N\\Exp\\qty(X_i)=\\frac1N\\sum_{i=1}^N\\mu=\\mu,\\\\\n\\Exp\\qty(\\bar{\\sigma}^2)&=\\frac{1}{N-1}\\Exp\\qty[\\sum_{i=1}^N(X_i-\\bar{\\mu})^2]=\\frac{1}{N-1}\\sum_{i=1}^N\\Exp\\mqty[\\qty(X_i-\\bar{\\mu})^2]\\\\\n&=\\frac{1}{N-1}\\sum_{i=1}^N\\qty(\\Var\\qty(X_i-\\bar{\\mu})+\\qty(\\Exp\\qty(X_i-\\bar{\\mu}))^2)\\\\\n&=\\frac{1}{N-1}\\sum_{i=1}^N\\qty(\\Var\\qty(\\frac{N-1}{N}X_i-\\frac1NX_1-\\ldots-\\frac1NX_N)+\\qty(\\Exp\\qty(X_i)-\\Exp\\qty(\\bar{\\mu}))^2)\\\\\n&=\\frac{1}{N-1}\\sum_{i=1}^N\\qty(\\frac{(N-1)^2}{N^2}\\Var\\qty(X_i)+\\frac1{N^2}\\Var\\qty(X_1)+\\ldots+\\frac1{N^2}\\Var\\qty(X_N))\\\\\n&=\\frac{1}{N-1}\\sum_{i=1}^N\\qty(\\frac{(N-1)^2}{N^2}\\sigma^2+\\frac1{N^2}\\sigma^2+\\ldots+\\frac1{N^2}\\sigma^2)\\\\\n&=\\frac{N}{N-1}\\frac{(N-1)^2+N-1}{N^2}\\sigma^2=\\sigma^2.\n\\end{aligned}\n$$\n\n:::\n\n\n::: {#def-}\nThe following are the unbiased estimators of $\\mu$ and $\\sigma^2$ of $X$.\n\n1. $\\bar{\\mu}=\\dfrac1N\\sum_{i=1}^NX_i$ is called the *sample mean* of the samples. \n2. $\\bar{\\sigma}^2=\\dfrac{1}{N-1}\\sum_{i=1}^N(X_i-\\bar{\\mu})^2$ is called the *sample variance* of the samples.\n\n\n:::\n\n\n::: {.callout-caution}\nPlease pay attention to the denominator of the sample variance. The $N-1$ is due to the degree of freedom: all $X_i$'s and $\\bar{\\mu}$ are not independent to each other.\n:::\n\n\n\n### Confidence intervals\n\n::: {#def-}\n# Confidence interval\nConsider a sample of $X$. Fix a number $0<\\alpha<1$. Let $L$ and $U$ be two statistics. We say the interval $(L,U)$ is a $(1-\\alpha)100\\%$ **confidence interval** for $\\theta$ if \n\n$$\n1-\\alpha=\\Pr[\\theta\\in(L,U)].\n$$\n:::\n\n\n::: {#thm-}\n# Large-Sample $100(1-\\alpha)\\%$ Confidence interval\n$$\nL,U=\\bar{\\mu}\\pm z_{\\alpha/2}\\qty(\\frac{\\bar{\\sigma}}{\\sqrt{n}}),\n$$\nwhere $z_{\\alpha/2}=1.96$ if $\\alpha=5\\%$.\n\n:::\n\n- For any $n$, if $X_i\\sim \\mathcal N(\\mu, \\sigma^2)$, $T_n=\\dfrac{\\bar{X}-\\mu}{S/\\sqrt{n}}$ has a Student's $t$-distribution of degree of freedom $n-1$. \n- When $n$ is big enough, for any distribution $X_i$, $Z_n=\\dfrac{\\bar{X}-\\mu}{S/\\sqrt{n}}$ is approximately $\\mathcal N(0,1)$. \n- Student's $t$-distribution of degree of freedom $n-1$ is approaching $\\mathcal N(0,1)$ when $n$ is increasing. When $n=30$ they are very close to each other. Therefore in many cases Statisticians require sample size $\\geq30$.\n- For large sample or small sample, the coefficients to compute confidence intervals are $z_{\\alpha/2}$ or $t_{\\alpha/2}$. These two numbers come from normal distribution or Student's $t$-distribution.\n\n\n\n## Hypothesis test\nElements of a Statistical Test of Hypothesis \n\n- Null Hypothesis $ð»_0$ \n- Alternative Hypothesis $ð»_ð‘Ž$ \n- Test Statistic \n- Level of significance $\\alpha$ \n- Rejection Region \n- $ð‘ƒ$-Value \n- Conclusion\n\n\n\n\n\n\n::: {.callout-note}\n# Type I error vs Type II error\n\nHypothesis test is built around the idea to control Type I error (=reducing false positive rate=increasing precision), since the significance level $\\alpha$ is the probability of Type I errors (=the probability of rejecting $H_0$ when $H_0$ is actually right). \n\nWhen using Hypothesis test, the scenario is usually that people capture some signals in order to prove an effect happens. The null hypothesis ($H_0$) is assumed to be the default case, and they want to make sure that once the signal is captured, the effect happens. In this case it is ok to miss some events that happens without the signal. In other words, people prioritize not making a false claim than missing an opportunity.\n:::\n\n\n\n\n\n\n![](assests/img/20250118234700.png)\n![](assests/img/20250118234719.png)\n![](assests/img/20250118234743.png)\n\n\n![](assests/img/20250118234802.png)\n\n![](assests/img/20250118234822.png)\n\n\n\n\n## best linear unbiased estimator (BLUE)\n\n![](assests/img/20250118234628.png)\n\n\n\nThe distribution of a statistic is called the sampling distribution.\n\nKey Points:\nA statistic is a numerical value calculated from a sample (e.g., sample mean, sample proportion, or sample variance).\nThe sampling distribution describes the probability distribution of that statistic across all possible samples of a given size from the population.\nExample:\nIf you repeatedly draw samples of size \nð‘›\nn from a population and calculate the sample mean (\nð‘¥\nË‰\nx\nË‰\n ) for each sample, the distribution of these sample means is the sampling distribution of the sample mean.\nSimilarly, if you calculate a proportion or variance for each sample, their distributions across samples are the sampling distributions of the sample proportion or sample variance, respectively.\nThe concept of a sampling distribution is foundational in inferential statistics, as it underpins methods like hypothesis testing and the construction of confidence intervals.\n\n\n\n![](assests/img/20250118234124.png)\n\n\n![](assests/img/20250118234212.png)\n\n\n![](assests/img/20250118234239.png)\n\n![](assests/img/20250118234253.png)\n\n\n![](assests/img/20250118234347.png)\n\n![](assests/img/20250118234359.png)\n\n\n![](assests/img/20250118234413.png)\n\n![](assests/img/20250118234428.png)\n\n![](assests/img/20250118234440.png)\n\n![](assests/img/20250118234454.png)\n\n\n![](assests/img/20250118234513.png)","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"toc-depth":2,"output-file":"inferences.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.3","number-depth":4,"bibliography":["../../book.bib"],"csl":"../../ims.csl","jupyter":"ds25","knitr":{"opts_chunk":{"comment":"#>","collapse":true}},"crossref":{"appendix-title":"Appendix ","appendix-delim":":"},"theme":"united"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}